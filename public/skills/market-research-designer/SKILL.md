---
name: market-research-designer
description: Designs research methodologies including surveys, focus groups, discussion guides, sample sizing, and analysis frameworks.
---

# Market Research Designer

A comprehensive framework for designing market research studies from brief through analysis. This skill covers methodology selection, instrument design, sampling strategy, and analysis planning to ensure research produces actionable, statistically sound insights.

## When to Use

- A client needs to understand their target audience before a campaign or product launch
- Validating brand positioning, messaging, or creative concepts
- Measuring customer satisfaction, brand health, or market share
- Exploring a new market or category for entry strategy
- Testing pricing, packaging, or product feature prioritization
- Gathering evidence for a strategic recommendation or business case
- Post-campaign effectiveness measurement

## Research Design Process

### Step 1: Define Research Objectives

Every study starts with clear, answerable objectives. Poor objectives produce unusable research.

**Objective framework:**
- **Business question**: What decision will this research inform?
- **Research question**: What do we need to learn to answer the business question?
- **Hypothesis** (if applicable): What do we expect to find, and why?
- **Success criteria**: What would a useful answer look like?
- **Scope boundaries**: What is explicitly out of scope?

**Example transformation:**
- Bad: "We want to understand our customers better."
- Good: "We need to identify which 3 product features drive purchase decisions among first-time buyers aged 25-40 in the US market, to prioritize our Q3 product roadmap."

### Step 2: Select Methodology

Choose the approach based on what you need to learn, timeline, and budget.

**Decision matrix:**

| Need | Best Method | Timeline | Relative Cost |
|---|---|---|---|
| Explore unknown attitudes/motivations | Depth interviews | 3-4 weeks | Medium |
| Understand group dynamics and reactions | Focus groups | 3-5 weeks | Medium-High |
| Observe real behavior in context | Ethnography | 4-8 weeks | High |
| Measure prevalence of attitudes at scale | Quantitative survey | 2-4 weeks | Medium |
| Test specific hypotheses with data | A/B testing | 2-6 weeks | Low-Medium |
| Evaluate feature/benefit tradeoffs | Conjoint analysis | 3-5 weeks | Medium-High |
| Monitor ongoing sentiment | Social listening | Ongoing | Low |
| Assess existing content and comms | Content audit | 1-2 weeks | Low |

### Step 3: Design the Sample

**Key sampling decisions:**
- **Population definition**: Who are we studying? Be specific about demographics, behaviors, and qualifying criteria.
- **Sampling method**: Probability (random, stratified, cluster) vs. non-probability (convenience, quota, snowball, purposive).
- **Sample size**: Driven by desired confidence level, margin of error, and population variability.
- **Recruitment approach**: Panel, client database, intercept, social media, referral.

**Sample sizing guidelines for quantitative research:**
- Population under 1,000 -- sample 30% minimum
- Population 1,000-10,000 -- n=300-400 for +/-5% margin at 95% confidence
- Population 10,000-100,000 -- n=385 for +/-5% margin at 95% confidence
- Population over 100,000 -- n=385-1,067 depending on desired precision
- For subgroup analysis, each subgroup needs minimum n=30 (ideally n=100+)

**Sample sizing for qualitative research:**
- Depth interviews -- 12-30 participants (saturation typically at 12-15)
- Focus groups -- 3-6 groups of 6-8 participants each
- Ethnography -- 8-15 participants minimum
- Usability testing -- 5-8 participants per distinct user segment

### Step 4: Build the Timeline

**Typical phase durations:**
1. Brief and objective alignment -- 2-3 days
2. Methodology and instrument design -- 3-5 days
3. Client review and approval -- 2-3 days
4. Recruitment -- 5-10 days (qualitative) or 1-3 days (panel survey)
5. Fieldwork -- 3-10 days (qual) or 5-14 days (quant)
6. Analysis -- 5-10 days
7. Report writing and design -- 3-5 days
8. Presentation and debrief -- 1-2 days

**Total typical range:** 4-8 weeks for a standard project.

## Qualitative Methodology Deep Dive

### Focus Groups

**When to use:** Exploring reactions, generating ideas, understanding group dynamics, testing concepts where peer influence matters.

**Group composition guidelines:**
- 6-8 participants per group (smaller for sensitive topics, larger for brainstorming)
- Homogeneous within groups on key segmentation variable
- Heterogeneous across groups to capture different perspectives
- Minimum 3 groups per segment for pattern reliability
- Separate groups for significantly different demographics (age, income, usage level)

**Discussion guide structure:**
1. **Welcome and ground rules** (5-10 min) -- introduce purpose, confidentiality, recording consent, "no wrong answers"
2. **Warm-up** (5-10 min) -- easy, open questions to build comfort and context
3. **Core exploration** (40-50 min) -- primary research questions, stimulus presentation, probing
4. **Synthesis and prioritization** (10-15 min) -- ranking exercises, summary questions
5. **Wrap-up** (5 min) -- anything unsaid, final thoughts

**Probing techniques:**
- Silence -- wait 5-7 seconds after a response before moving on
- Echo -- repeat the last few words as a question
- Ladder -- "Why is that important to you?" repeated to reach deeper motivations
- Third-party projection -- "What would your friends think about this?"
- Sentence completion -- "The ideal version of this would be..."

### Depth Interviews

**When to use:** Sensitive topics, complex decision journeys, expert perspectives, B2B research, topics where group influence would bias responses.

**Interview guide principles:**
- Start broad, narrow progressively (funnel approach)
- Use open-ended questions -- avoid leading or binary questions
- Prepare 8-12 main questions for a 45-60 minute interview
- Write 2-3 follow-up probes for each main question
- Include one projective or creative exercise to access implicit attitudes

### Ethnography

**When to use:** Understanding behavior in natural context, identifying unarticulated needs, exploring the gap between what people say and what they do.

**Key methods:**
- In-home or in-context observation
- Shop-alongs and ride-alongs
- Diary studies (photo, video, or written journals)
- Digital ethnography (social media, forums, community observation)
- Contextual inquiry (observe then interview in situ)

## Quantitative Methodology Deep Dive

### Survey Design Principles

**Question writing rules:**
1. One concept per question -- never double-barreled
2. Avoid leading language -- neutral framing only
3. Provide balanced scales -- equal positive and negative options
4. Include "not applicable" and "prefer not to say" where appropriate
5. Randomize response option order where possible to avoid primacy bias
6. Keep surveys under 15 minutes (ideally 8-10 minutes)
7. Place sensitive questions toward the end after rapport is established
8. Use consistent scale directions throughout

**Scale recommendations:**
- Agreement: 5-point Likert (Strongly disagree to Strongly agree)
- Satisfaction: 5 or 7-point scale with labeled endpoints
- NPS: Standard 0-10 scale with standard promoter/detractor classification
- Importance: 5-point scale or MaxDiff for relative importance
- Frequency: Specific time periods, not vague terms like "often" or "sometimes"

**Survey flow:**
1. Screener questions (to qualify or disqualify)
2. Warm-up -- easy behavioral questions
3. Core -- primary research questions
4. Supporting -- secondary and contextual questions
5. Demographics -- always last unless needed for screening

### A/B Testing

**Design requirements:**
- Single variable isolation -- test one change at a time
- Sufficient sample size for statistical power (use power calculators)
- Randomized assignment to control and test groups
- Predetermined success metric and minimum detectable effect
- Run duration long enough to capture full cycles (typically 2-4 weeks minimum)
- Document all external factors that could influence results

### Conjoint Analysis

**When to use:** Understanding tradeoffs between product features, pricing sensitivity, package optimization, competitive simulation.

**Design steps:**
1. Identify attributes (3-6 typically)
2. Define levels for each attribute (2-5 per attribute)
3. Generate experimental design (full factorial or fractional)
4. Build choice tasks (typically 8-15 per respondent)
5. Determine sample size (minimum 200, ideally 300+)
6. Analyze with hierarchical Bayesian estimation or logit models

## Analysis Frameworks

### Qualitative Analysis

- **Thematic analysis**: Code transcripts, identify patterns, group into themes, validate across sources
- **Framework analysis**: Matrix-based approach mapping themes against participants or segments
- **Affinity diagramming**: Group verbatim quotes and observations into clusters
- **Narrative analysis**: Trace story arcs and decision journeys across participants

### Quantitative Analysis

- **Descriptive statistics**: Frequencies, means, cross-tabulations
- **Significance testing**: Chi-square for categorical, t-tests for means, ANOVA for multi-group
- **Segmentation**: Cluster analysis, latent class analysis
- **Driver analysis**: Regression, SHAPLEY value, key driver analysis
- **Text analytics**: Sentiment analysis, topic modeling for open-ended responses

## Research Brief Template

```
# Research Brief: [Project Name]

## Background
[Business context and what prompted this research need]

## Business Decision
[The specific decision this research will inform]

## Research Objectives
1. [Primary objective]
2. [Secondary objective]
3. [Secondary objective]

## Target Audience
- Primary: [Description with demographics and behavioral criteria]
- Secondary: [If applicable]
- Exclusions: [Who should NOT be included]

## Methodology Recommendation
[Proposed approach with rationale]

## Sample Design
- Size: [n=X]
- Segments: [Breakdown by key variables]
- Recruitment: [Source and approach]

## Timeline
- Kickoff: [Date]
- Fieldwork: [Date range]
- Preliminary findings: [Date]
- Final deliverable: [Date]

## Budget Range
[Estimated investment]

## Deliverables
- [List of expected outputs]

## Key Stakeholders
- [Name, role, involvement level]
```

## Common Research Pitfalls

1. **Confirmation bias**: Designing questions that confirm what stakeholders already believe
2. **Leading questions**: Framing that pushes respondents toward a particular answer
3. **Sampling bias**: Recruiting only easily accessible or enthusiastic participants
4. **Survey fatigue**: Instruments too long, causing dropoff or random responding
5. **Small base reporting**: Drawing conclusions from subgroups with n less than 30
6. **Conflating correlation and causation**: Observational research cannot prove causation
7. **Anchoring**: Early questions influencing responses to later questions
8. **Social desirability**: Respondents answering how they think they should, not how they actually feel
9. **Recency bias**: Over-weighting recent experiences in recall-based questions
10. **Scope creep**: Adding questions mid-field, compromising data integrity and timeline

## Quality Checklist

- [ ] Research objectives directly connect to a stated business decision
- [ ] Methodology matches the type of insight needed (exploratory vs. confirmatory)
- [ ] Sample size is sufficient for intended analysis and subgroup comparisons
- [ ] Screener criteria clearly define who qualifies and who does not
- [ ] Survey or discussion guide has been piloted with 3-5 test respondents
- [ ] Questions are neutral, single-concept, and use consistent scales
- [ ] Analysis plan is defined before fieldwork begins -- not reverse-engineered
- [ ] Timeline includes buffer for recruitment challenges and client review cycles
- [ ] Incentive levels are appropriate for the audience and time commitment
- [ ] Deliverable format and presentation date are agreed upon upfront
- [ ] Raw data handling and privacy comply with relevant regulations (GDPR, CCPA)
- [ ] Limitations of the methodology are documented and communicated to stakeholders
